{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "222cbe2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s5/jmvhvqns52q3ysypfjykg6y40000gr/T/ipykernel_69306/2827350927.py:18: UserWarning: Shapely 2.0 is installed, but because PyGEOS is also installed, GeoPandas will still use PyGEOS by default for now. To force to use and test Shapely 2.0, you have to set the environment variable USE_PYGEOS=0. You can do this before starting the Python process, or in your code before importing geopandas:\n",
      "\n",
      "import os\n",
      "os.environ['USE_PYGEOS'] = '0'\n",
      "import geopandas\n",
      "\n",
      "In a future release, GeoPandas will switch to using Shapely by default. If you are using PyGEOS directly (calling PyGEOS functions on geometries from GeoPandas), this will then stop working and you are encouraged to migrate from PyGEOS to Shapely 2.0 (https://shapely.readthedocs.io/en/latest/migration_pygeos.html).\n",
      "  import geopandas as gpd\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from plotters import plot_fit, plot_sensitivity_analysis\n",
    "from plotters.plot_fit import plot_fit_multiple, plot_runs\n",
    "from plotters.plot_sensitivity import generate_ethnicity_df, generate_social_df, generate_age_df, generate_district_df, get_newton_step, plot_sensitivity_analysis_multiple\n",
    "from plotters.plot_sensitivity import get_sensitivity_ethnicity_multiple, get_sensitivity_age_multiple, get_sensitivity_social_multiple, get_sensitivity_district_multiple\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "from matplotlib import dates as mdates\n",
    "from collections import defaultdict\n",
    "import matplotlib as mpl\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import geopandas as gpd\n",
    "from matplotlib.colors import LogNorm, SymLogNorm\n",
    "mpl.rcParams[\"figure.dpi\"] = 100\n",
    "\n",
    "from grad_june import Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51bcc54e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([PosixPath('../Data/June/london_fits/london_fit_011.yaml'),\n",
       "       PosixPath('../Data/June/london_fits/london_fit_007.yaml'),\n",
       "       PosixPath('../Data/June/london_fits/london_fit_000.yaml'),\n",
       "       PosixPath('../Data/June/london_fits/london_fit_017.yaml'),\n",
       "       PosixPath('../Data/June/london_fits/london_fit_019.yaml')],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_files = np.array(list(Path(\"../Data/June/london_fits\").glob(\"*.yaml\")))[[2, 3, 4, 6, 11]]\n",
    "fit_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e3c50b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mplot_runs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfit_files\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/one_shot_sensitivity/notebooks/../plotters/plot_fit.py:115\u001b[0m, in \u001b[0;36mplot_runs\u001b[0;34m(files, window, days)\u001b[0m\n\u001b[1;32m    113\u001b[0m parameters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:5\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    114\u001b[0m parameters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimer\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal_days\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m days\n\u001b[0;32m--> 115\u001b[0m runner \u001b[38;5;241m=\u001b[39m \u001b[43mRunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m results, _ \u001b[38;5;241m=\u001b[39m runner()\n\u001b[1;32m    118\u001b[0m \u001b[38;5;66;03m# deaths\u001b[39;00m\n",
      "File \u001b[0;32m~/code/gradabm-june/grad_june/runner.py:50\u001b[0m, in \u001b[0;36mRunner.from_parameters\u001b[0;34m(cls, params)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_parameters\u001b[39m(\u001b[38;5;28mcls\u001b[39m, params):\n\u001b[0;32m---> 50\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mTorchJune\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mget_data(params)\n\u001b[1;32m     52\u001b[0m     timer \u001b[38;5;241m=\u001b[39m Timer\u001b[38;5;241m.\u001b[39mfrom_parameters(params)\n",
      "File \u001b[0;32m~/code/gradabm-june/grad_june/model.py:47\u001b[0m, in \u001b[0;36mTorchJune.from_parameters\u001b[0;34m(cls, params)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_parameters\u001b[39m(\u001b[38;5;28mcls\u001b[39m, params):\n\u001b[0;32m---> 47\u001b[0m     symptoms_updater \u001b[38;5;241m=\u001b[39m \u001b[43mSymptomsUpdater\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m     policies \u001b[38;5;241m=\u001b[39m Policies\u001b[38;5;241m.\u001b[39mfrom_parameters(params)\n\u001b[1;32m     49\u001b[0m     infection_networks \u001b[38;5;241m=\u001b[39m InfectionNetworks\u001b[38;5;241m.\u001b[39mfrom_parameters(params)\n",
      "File \u001b[0;32m~/code/gradabm-june/grad_june/symptoms.py:146\u001b[0m, in \u001b[0;36mSymptomsUpdater.from_parameters\u001b[0;34m(cls, params)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_parameters\u001b[39m(\u001b[38;5;28mcls\u001b[39m, params):\n\u001b[0;32m--> 146\u001b[0m     ss \u001b[38;5;241m=\u001b[39m \u001b[43mSymptomsSampler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(symptoms_sampler\u001b[38;5;241m=\u001b[39mss)\n",
      "File \u001b[0;32m~/code/gradabm-june/grad_june/symptoms.py:42\u001b[0m, in \u001b[0;36mSymptomsSampler.from_parameters\u001b[0;34m(cls, params)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_parameters\u001b[39m(\u001b[38;5;28mcls\u001b[39m, params):\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msymptoms\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdevice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/gradabm-june/grad_june/symptoms.py:25\u001b[0m, in \u001b[0;36mSymptomsSampler.__init__\u001b[0;34m(self, stages, stage_transition_probabilities, stage_transition_times, recovery_times, device)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstages \u001b[38;5;241m=\u001b[39m stages\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstages_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(stages))\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstage_transition_probabilities \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m---> 25\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_stage_transition_probabilities\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstage_transition_probabilities\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m )\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstage_transition_times \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_stage_times(\n\u001b[1;32m     30\u001b[0m     stage_transition_times, device\u001b[38;5;241m=\u001b[39mdevice\n\u001b[1;32m     31\u001b[0m )\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecovery_times \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_stage_times(recovery_times, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[0;32m~/code/gradabm-june/grad_june/symptoms.py:47\u001b[0m, in \u001b[0;36mSymptomsSampler._parse_stage_transition_probabilities\u001b[0;34m(self, stage_transition_probabilities, device)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_parse_stage_transition_probabilities\u001b[39m(\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28mself\u001b[39m, stage_transition_probabilities, device\n\u001b[1;32m     46\u001b[0m ):\n\u001b[0;32m---> 47\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstages\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, stage \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstages):\n\u001b[1;32m     49\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m stage \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m stage_transition_probabilities:\n",
      "File \u001b[0;32m~/miniconda3/envs/p10/lib/python3.10/site-packages/torch/cuda/__init__.py:221\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 221\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "plot_runs(fit_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590083f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_fit_multiple(fit_files, window=7, days=61, errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6ab97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sensitivity_analysis_multiple(fit_files, days=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee05488",
   "metadata": {},
   "source": [
    "# Ethnicity plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cc011b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_ethn = generate_ethnicity_df(r, n=1)\n",
    "df_ethn = get_sensitivity_ethnicity_multiple(fit_files, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb7dbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "toplot = pd.concat(df_ethn)\n",
    "toplot = toplot.loc[[\"household\", \"school\", \"company\", \"university\"]]\n",
    "toplot = toplot.rename(columns={\"A\" : \"White\", \"B\" : \"Mixed\", \"C\": \"Asian\", \"D\": \"Black\", \"E\": \"Other\"})\n",
    "toplot = toplot.rename({\"company\": \"Company\", 'school' : 'School', \"household\" : \"Household\", \"university\" : \"University\"})\n",
    "mean = toplot.groupby(toplot.index).mean()\n",
    "std = toplot.groupby(toplot.index).std()\n",
    "fig, ax = plt.subplots()\n",
    "mean.plot.barh(ax=ax, xerr=std, capsize=3, width=0.8)\n",
    "ax.set_xlabel(r\"Sensitivity of $f^d$\")\n",
    "ax.legend(title=\"Ethnicity\")\n",
    "fig.savefig(\"../figures/sensitivity_ethnicity.png\", dpi=150, bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2aaff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_social = generate_social_df(r, n=1)\n",
    "df_social = get_sensitivity_social_multiple(fit_files, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99e45dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "toplot = pd.concat(df_social)\n",
    "toplot = toplot.loc[[\"household\", \"school\", \"company\", \"university\"]]\n",
    "toplot = toplot.rename({\"company\": \"Company\", 'school' : 'School', \"household\" : \"Household\", \"university\" : \"University\"})\n",
    "toplot = toplot.rename(columns={1: \"1 (least deprived)\", 5: \"5 (most deprived)\"})\n",
    "\n",
    "mean = toplot.groupby(toplot.index).mean()\n",
    "std = toplot.groupby(toplot.index).std()\n",
    "fig, ax = plt.subplots()\n",
    "mean.plot.barh(ax=ax, xerr=std, capsize=3, width=0.8)\n",
    "ax.set_xlabel(r\"Sensitivity of $f^d$\")\n",
    "ax.legend(title=\"IMD quintile\")\n",
    "fig.savefig(\"../figures/sensitivity_social.png\", dpi=150, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6741a835",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_age = generate_age_df(r, date=\"2020-03-03\", n=1)\n",
    "df_age = get_sensitivity_age_multiple(fit_files, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466c6c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "toplot = pd.concat(df_age)\n",
    "toplot = toplot.loc[[\"household\", \"school\", \"company\", \"university\"]]\n",
    "toplot = toplot.rename({\"company\": \"Company\", 'school' : 'School', \"household\" : \"Household\", \"university\": \"University\"})\n",
    "toplot = toplot.rename(columns={18: \"0-17\", 25 : \"18-24\", 35 : \"25-34\", 45: \"35-44\", 55 : \"45-54\", 65: \"55-64\", 75 : \"65-74\", 100: \"75+\"})\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "mean = toplot.groupby(toplot.index).mean()\n",
    "std = toplot.groupby(toplot.index).std()\n",
    "mean.plot.barh(ax=ax, xerr=std, capsize=3, width=0.8)\n",
    "ax.set_xlabel(r\"Sensitivity of $f^d$\")\n",
    "ax.legend(title=\"Age bin\", ncol=2)\n",
    "fig.savefig(\"../figures/sensitivity_age.png\", dpi=150, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8522c9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "district_ids = [276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289,\n",
    "        290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303,\n",
    "        304, 305, 306, 307, 308]\n",
    "district_df = pd.read_csv(\"../../GradABM/Data/June/area_district.csv\")\n",
    "district_df = district_df.loc[district_df.id.isin(district_ids)]\n",
    "district_df.set_index(\"id\", inplace=True)\n",
    "district_df.sort_index(inplace=True)\n",
    "district_names = district_df[\"ladnm\"].drop_duplicates().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3283d3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapefiles = gpd.read_file(\"../statistical-gis-boundaries-london/ESRI/London_Borough_Excluding_MHW.shp\")\n",
    "shapefiles = shapefiles.set_index(\"NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3355812a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_district = generate_district_df(r, n=5)\n",
    "df_district = get_sensitivity_district_multiple(fit_files, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efcf772",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_district = pd.concat(df_district)\n",
    "df_district_std = df_district.groupby(df_district.index).std()\n",
    "df_district = df_district.groupby(df_district.index).mean()\n",
    "\n",
    "df_district_std.columns = district_names\n",
    "df_district.columns = district_names\n",
    "df_district = df_district.transpose()\n",
    "df_district_std = df_district_std.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35e9252",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_df = pd.merge(shapefiles, df_district, left_index=True, right_index=True)\n",
    "geo_df_std = pd.merge(shapefiles, df_district_std, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6332be",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(2,2)\n",
    "\n",
    "geo_df.plot(\"household\", ax=ax[0,0], norm=SymLogNorm(1e-4))#, legend=True, norm=SymLogNorm(1e-4, vmin=-1e-1, vmax=1e-1))\n",
    "geo_df.plot(\"school\", ax=ax[0,1], norm=SymLogNorm(1e-4))\n",
    "geo_df.plot(\"company\", ax=ax[1,0], norm=SymLogNorm(1e-4))\n",
    "geo_df.plot(\"university\", ax=ax[1,1], norm=SymLogNorm(1e-4))\n",
    "\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax[i, j].set_xticks([])\n",
    "        ax[i, j].set_yticks([])\n",
    "    \n",
    "#ax[1].set_title(\"Sensitivity by district\")\n",
    "ax[0,0].set_title(\"Household\")\n",
    "ax[0,1].set_title(\"School\")\n",
    "ax[1,0].set_title(\"Company\")\n",
    "ax[1,1].set_title(\"University\")\n",
    "\n",
    "plt.subplots_adjust(wspace=0.05, hspace=0.2)\n",
    "f.savefig(\"../figures/sensitivity_district.png\", dpi=150, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3238e7ac",
   "metadata": {},
   "source": [
    "# Optimal policy setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed07e38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gradient(file, date_str):\n",
    "    date = datetime.datetime.strptime(date_str, \"%Y-%m-%d\")\n",
    "    n_days = (date - datetime.datetime.strptime(\"2020-03-01\", \"%Y-%m-%d\")).days\n",
    "    params = yaml.safe_load(open(file))\n",
    "    params[\"timer\"][\"total_days\"] = n_days\n",
    "    params[\"system\"][\"device\"] = \"cpu\"\n",
    "    r = Runner.from_parameters(params)\n",
    "\n",
    "    for network in r.model.infection_networks.networks:\n",
    "        r.model.infection_networks.networks[network].log_beta = torch.nn.Parameter(r.model.infection_networks.networks[network].log_beta)\n",
    "    results, _ = r()\n",
    "    cases = results[\"cases_per_timestep\"][-1]\n",
    "    cases.backward()\n",
    "    ret = {}\n",
    "    norm = 0\n",
    "    for network in r.model.infection_networks.networks:\n",
    "        v = r.model.infection_networks.networks[network].log_beta.grad.item()\n",
    "        norm += v**2\n",
    "        ret[network] = v\n",
    "    norm = np.sqrt(norm)\n",
    "    for key in ret:\n",
    "        ret[key] = ret[key] / norm\n",
    "    return ret\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ec0a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_params(file, gradients):\n",
    "    params = yaml.safe_load(open(file))\n",
    "    params[\"timer\"][\"total_days\"] = 60\n",
    "    params[\"system\"][\"device\"] = \"cuda:8\"\n",
    "    params[\"policies\"][\"interaction\"][\"social_distancing\"] = {}\n",
    "    params[\"policies\"][\"interaction\"][\"social_distancing\"][1] = {}\n",
    "    params[\"policies\"][\"interaction\"][\"social_distancing\"][1][\"start_date\"] = \"2020-03-16\"\n",
    "    params[\"policies\"][\"interaction\"][\"social_distancing\"][1][\"end_date\"] = \"2021-03-16\"\n",
    "    params[\"policies\"][\"interaction\"][\"social_distancing\"][1][\"beta_factors\"] = {}\n",
    "    for key in gradients:\n",
    "        if key == \"household\":\n",
    "            continue\n",
    "        old_beta = 10**(params[\"networks\"][key][\"log_beta\"])\n",
    "        delta_beta = gradients[key] * old_beta\n",
    "        new_beta = old_beta -  delta_beta # derivative of the log\n",
    "        factor = new_beta / old_beta\n",
    "        params[\"policies\"][\"interaction\"][\"social_distancing\"][1][\"beta_factors\"][key] = factor\n",
    "    return params\n",
    "\n",
    "def run_for_policy(params):\n",
    "    with torch.no_grad():\n",
    "        r = Runner.from_parameters(params)\n",
    "        results, _ = r()\n",
    "        return np.array(results[\"dates\"]), results[\"cases_per_timestep\"].cpu().numpy()\n",
    "    \n",
    "def run_vanilla(file):\n",
    "    params = yaml.safe_load(open(file))\n",
    "    params[\"timer\"][\"total_days\"] = 60\n",
    "    params[\"system\"][\"device\"] = \"cuda:8\"\n",
    "    with torch.no_grad():\n",
    "        r = Runner.from_parameters(params)\n",
    "        results, _ = r()\n",
    "        return np.array(results[\"dates\"]), results[\"cases_per_timestep\"].cpu().numpy()\n",
    "    \n",
    "def run_for_files(files):\n",
    "    results_opt = []\n",
    "    results_naive = []\n",
    "    results_vanilla = []\n",
    "    results_nop = []\n",
    "    for file in tqdm(files):\n",
    "        gradient = get_gradient(file, \"2020-03-15\")\n",
    "        naive_grad = {key: 1 / len(gradient) for key in gradient}\n",
    "        \n",
    "        params_opt = generate_params(file, gradient)\n",
    "        dates_opt, res_opt = run_for_policy(params_opt)\n",
    "        results_opt.append(res_opt)\n",
    "        \n",
    "        params_naive = generate_params(file, naive_grad)\n",
    "        dates_naive, res_naive = run_for_policy(params_naive)\n",
    "        results_naive.append(res_naive)\n",
    "        \n",
    "        dates_vanilla, res_vanilla = run_vanilla(file)\n",
    "        results_vanilla.append(res_vanilla)\n",
    "        \n",
    "        params_nop = generate_params(file, {key: 0.0 for key in gradient})\n",
    "        dates_nop, res_nop = run_for_policy(params_nop)\n",
    "        results_nop.append(res_nop)\n",
    "        \n",
    "    return dates_opt, np.array(results_opt), np.array(results_naive), np.array(results_vanilla), np.array(results_nop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cb24ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates, results_opt, results_naive, results_vanilla, results_nop = run_for_files(fit_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fafa8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_opt = np.array(results_opt)\n",
    "results_naive = np.array(results_naive)\n",
    "results_vanilla = np.array(results_vanilla)\n",
    "results_nop = np.array(results_nop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6e3c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots()\n",
    "ax.plot(dates, results_opt.mean(0), label = \"Optimal cost-effective lockdown\")\n",
    "ax.plot(dates, results_naive.mean(0), label = \"Naive cost-effective lockdown\")\n",
    "ax.plot(dates, results_vanilla.mean(0), label = \"Real lockdown\")\n",
    "ax.plot(dates, results_nop.mean(0), label = \"No lockdown\")\n",
    "\n",
    "alpha = 0.25\n",
    "ax.fill_between(dates, results_opt.mean(0) - results_opt.std(0), results_opt.mean(0) + results_opt.std(0), alpha=alpha, linewidth=0)\n",
    "ax.fill_between(dates, results_naive.mean(0) - results_naive.std(0), results_naive.mean(0) + results_naive.std(0), alpha=alpha, linewidth=0)\n",
    "ax.fill_between(dates, results_vanilla.mean(0) - results_vanilla.std(0), results_vanilla.mean(0) + results_vanilla.std(0), alpha=alpha, linewidth=0)\n",
    "ax.fill_between(dates, results_nop.mean(0) - results_nop.std(0), results_nop.mean(0) + results_nop.std(0), alpha=alpha, linewidth=0)\n",
    "\n",
    "ax.set_yscale(\"log\")\n",
    "fmt_month = mdates.MonthLocator()\n",
    "ax.xaxis.set_major_locator(fmt_month)\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%b\"))\n",
    "ax.axvline(datetime.datetime.strptime(\"2020-03-15\", \"%Y-%m-%d\"), color = \"black\", linestyle=\"--\", linewidth=1)\n",
    "ax.set_ylabel(\"Cumulative cases\")\n",
    "ax.legend()\n",
    "f.savefig(\"../figures/optimal_lockdown.png\", dpi=150, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cdf7f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000431d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6ff69a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p10",
   "language": "python",
   "name": "p10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
